"""
chatbot_service.py
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
í…ìŠ¤íŠ¸ ê°ì • + ìŒì„±(ì˜¤ë””ì˜¤ ì„ë² ë”©) ê¸°ë°˜ ìŠ¤íŠ¸ë ˆìŠ¤ ë¶„ì„ì„ ë™ì‹œì— ì²˜ë¦¬í•˜ëŠ”
ChatbotService êµ¬í˜„.

â€¢ LLM            : OpenAI GPT-4 / GPT-3.5-turbo (langchain_openai.ChatOpenAI)
â€¢ í…ìŠ¤íŠ¸ ê°ì •    : j-hartmann/emotion-english-distilroberta-base
â€¢ ìŒì„± ìŠ¤íŠ¸ë ˆìŠ¤   : forwarder1121/voice-based-stress-recognition  (StudentNet)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
"""
from __future__ import annotations

import os
from dataclasses import dataclass
from typing import Dict, Tuple, List, Any, Optional

import torch
import torchaudio
from huggingface_hub import login as hf_login
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    AutoConfig,
    AutoModelForAudioClassification,
    pipeline,
)
from langchain_openai import ChatOpenAI

from src.app.constants import DEFAULT_PERSONA, PERSONA_PROMPTS
from src.utils.error_handling import handle_streamlit_errors
from src.utils.rag_utils import RAGUtils

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ HF ëª¨ë¸ ID & ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_EMOTION_MODEL_ID = "j-hartmann/emotion-english-distilroberta-base"

_STRESS_REPO   = "forwarder1121/voice-based-stress-recognition"
_W2V_PIPELINE  = torchaudio.pipelines.WAV2VEC2_BASE          # 512-dim
_DEVICE        = torch.device("cpu")                        # â† CPU ê³ ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


@dataclass
class ChatbotService:
    """
    - analyze_emotion(text)  â†’ ê°ì • 7-class í™•ë¥  dict
    - analyze_stress(wav)    â†’ {'not_stressed': p0, 'stressed': p1}
    - get_response(...)      â†’ LLM+RAG ì‘ë‹µ, ì°¸ì¡° ë¬¸ì„œ
    """

    def __init__(self, openai_config):
        # 0) HF í† í°(ìˆìœ¼ë©´) ë¡œê·¸ì¸
        hf_token = (
            os.getenv("HF_TOKEN")
            or os.getenv("HUGGINGFACEHUB_API_TOKEN")
            or os.getenv("HF_API_TOKEN")
        )
        if hf_token:
            hf_login(hf_token)

        # 1) LLM
        self.llm = ChatOpenAI(
            api_key=openai_config.api_key,
            model_name=openai_config.chat_model,
            temperature=openai_config.temperature,
        )

        # 2) í…ìŠ¤íŠ¸ ê°ì • ë¶„ë¥˜ê¸°
        self._init_text_emotion_classifier()

        # 3) ìŒì„± ìŠ¤íŠ¸ë ˆìŠ¤ ë¶„ë¥˜ê¸° + W2V ì„ë² ë”© ëª¨ë¸
        self._init_stress_classifier()

        # 4) RAG
        self._init_rag()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ í…ìŠ¤íŠ¸ ê°ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _init_text_emotion_classifier(self) -> None:
        """DistilRoBERTa ê°ì • ë¶„ë¥˜ê¸° (CPU ë¡œ ì™„ì „ ë¡œë“œ)"""
        os.environ["TOKENIZERS_PARALLELISM"] = "false"

        tok = AutoTokenizer.from_pretrained(_EMOTION_MODEL_ID)
        model = AutoModelForSequenceClassification.from_pretrained(
            _EMOTION_MODEL_ID,
            torch_dtype="float32",
            low_cpu_mem_usage=False,      # ë©”íƒ€-í…ì„œ ë°©ì§€
        ).to(_DEVICE).eval()

        self.emotion_classifier = pipeline(
            "text-classification",
            model=model,
            tokenizer=tok,
            top_k=None,
            device=-1,                   # ë‚´ë¶€ .to() í˜¸ì¶œ ì°¨ë‹¨
        )

    @handle_streamlit_errors
    def analyze_emotion(self, text: str) -> Dict[str, float]:
        results = self.emotion_classifier(text)
        return {x["label"]: x["score"] for x in results[0]}

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìŒì„± ìŠ¤íŠ¸ë ˆìŠ¤ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _init_stress_classifier(self) -> None:
        cfg = AutoConfig.from_pretrained(_STRESS_REPO, trust_remote_code=True)

        # StudentNet (2-class)
        self.stress_model = AutoModelForAudioClassification.from_pretrained(
            _STRESS_REPO,
            config=cfg,
            trust_remote_code=True,
            torch_dtype="float32",
            device_map={"": _DEVICE},
        ).eval()

        # Wav2Vec2 (512-dim ì„ë² ë”©)
        bundle = _W2V_PIPELINE
        self.w2v = bundle.get_model().to(_DEVICE).eval()
        self.resample = torchaudio.transforms.Resample(
            orig_freq=bundle.sample_rate, new_freq=16_000
        )

    @handle_streamlit_errors
    def analyze_stress(self, wav_path: str) -> Optional[Dict[str, float]]:
        """
        WAV â†’ {"stressed": p, "not_stressed": q}
        """
        wav, sr = torchaudio.load(wav_path)
        wav = wav.mean(dim=0, keepdim=True)
        if sr != 16_000:
            wav = self.resample(wav)

        with torch.inference_mode():
            feats_list, _ = self.w2v.extract_features(wav.to(_DEVICE))
            if not feats_list:
                return None

            feats = feats_list[-1]               # (1, T, 768)
            if feats.size(-1) > 512:             # ğŸ”¹ 768 â†’ 512
                feats = feats[..., :512]

            emb = feats.mean(dim=1)              # (1, 512)

            logits = self.stress_model(emb).logits
            probs  = torch.softmax(logits, dim=-1)[0]

        return {
            "not_stressed": float(probs[0]),
            "stressed":     float(probs[1]),
        }

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RAG â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    def _init_rag(self) -> None:
        try:
            self.rag_utils = RAGUtils()
            self.rag_enabled = True
            print("âœ… RAG enabled")
        except Exception as e:
            print(f"âš ï¸  RAG init failed: {e}")
            self.rag_enabled = False

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Chat ì‘ë‹µ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    @handle_streamlit_errors
    def get_response(
        self, user_input: str, persona_name: str
    ) -> Tuple[str, List[Dict[str, Any]]]:
        persona_prompt = PERSONA_PROMPTS.get(
            persona_name, PERSONA_PROMPTS[DEFAULT_PERSONA]
        )

        augmented_prompt, reference_docs = "", []
        if self.rag_enabled:
            try:
                augmented_prompt, reference_docs = self.rag_utils.get_augmented_prompt(
                    user_input, persona_name
                )
            except Exception:
                pass

        prompt = f"""
        {persona_prompt}

        {augmented_prompt}

        ì‚¬ìš©ì ë©”ì‹œì§€: {user_input}

        ìœ„ í˜ë¥´ì†Œë‚˜ ì„¤ì •ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ë©”ì‹œì§€ì— ê³µê°í•˜ê³  ì ì ˆí•œ ì‘ë‹µì„ í•´ì£¼ì„¸ìš”.
        ì‘ë‹µì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ í•´ì£¼ì„¸ìš”.
        ì‘ë‹µì—ëŠ” í˜ë¥´ì†Œë‚˜ì˜ íŠ¹ì§•ì´ ì˜ ë“œëŸ¬ë‚˜ì•¼ í•©ë‹ˆë‹¤.
        ì‘ë‹µì—ëŠ” 'í˜ë¥´ì†Œë‚˜ì˜ ë©”ì‹œì§€:', 'ì±—ë´‡ì˜ ë©”ì‹œì§€:' ë“±ì˜ ì ‘ë‘ì–´ë¥¼ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
        """

        response = self.llm.invoke(prompt)
        return response.content.strip(), reference_docs
